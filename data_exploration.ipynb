{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d831641-1d1f-4569-9d04-a3d7b320491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "\n",
    "import utils.data_processing_bronze_table\n",
    "import utils.data_processing_silver_table\n",
    "import utils.data_processing_gold_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4e7012-f875-4877-b8de-0e81ee15b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/07 12:56:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ba9a26-3f5b-4085-9523-d5a923412586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bronze datalake\n",
    "bronze_lms_directory = \"datamart/bronze/lms/\"\n",
    "\n",
    "if not os.path.exists(bronze_lms_directory):\n",
    "    os.makedirs(bronze_lms_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "657dc448-d553-4377-a377-d634b10dfc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LMS Loan Daily Data:\n",
      "+---------------------+-----------+---------------+------+---------------+--------+-------+--------+-----------+-------+-------------+\n",
      "|loan_id              |Customer_ID|loan_start_date|tenure|installment_num|loan_amt|due_amt|paid_amt|overdue_amt|balance|snapshot_date|\n",
      "+---------------------+-----------+---------------+------+---------------+--------+-------+--------+-----------+-------+-------------+\n",
      "|CUS_0x1000_2023_05_01|CUS_0x1000 |2023-05-01     |10    |0              |10000   |0.0    |0.0     |0.0        |10000.0|2023-05-01   |\n",
      "|CUS_0x1000_2023_05_01|CUS_0x1000 |2023-05-01     |10    |1              |10000   |1000.0 |1000.0  |0.0        |9000.0 |2023-06-01   |\n",
      "|CUS_0x1000_2023_05_01|CUS_0x1000 |2023-05-01     |10    |2              |10000   |1000.0 |1000.0  |0.0        |8000.0 |2023-07-01   |\n",
      "|CUS_0x1000_2023_05_01|CUS_0x1000 |2023-05-01     |10    |3              |10000   |1000.0 |0.0     |1000.0     |8000.0 |2023-08-01   |\n",
      "|CUS_0x1000_2023_05_01|CUS_0x1000 |2023-05-01     |10    |4              |10000   |1000.0 |2000.0  |0.0        |6000.0 |2023-09-01   |\n",
      "+---------------------+-----------+---------------+------+---------------+--------+-------+--------+-----------+-------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- loan_start_date: date (nullable = true)\n",
      " |-- tenure: integer (nullable = true)\n",
      " |-- installment_num: integer (nullable = true)\n",
      " |-- loan_amt: integer (nullable = true)\n",
      " |-- due_amt: double (nullable = true)\n",
      " |-- paid_amt: double (nullable = true)\n",
      " |-- overdue_amt: double (nullable = true)\n",
      " |-- balance: double (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "\n",
      "✅ Customer Attributes Data:\n",
      "+-----------+--------------+---+-----------+-------------+-------------+\n",
      "|Customer_ID|Name          |Age|SSN        |Occupation   |snapshot_date|\n",
      "+-----------+--------------+---+-----------+-------------+-------------+\n",
      "|CUS_0x1000 |Alistair Barrf|18 |913-74-1218|Lawyer       |2023-05-01   |\n",
      "|CUS_0x1009 |Arunah        |26 |063-67-6938|Mechanic     |2025-01-01   |\n",
      "|CUS_0x100b |Shirboni      |19 |#F%$D@*&8  |Media_Manager|2024-03-01   |\n",
      "|CUS_0x1011 |Schneyerh     |44 |793-05-8223|Doctor       |2023-11-01   |\n",
      "|CUS_0x1013 |Cameront      |44 |930-49-9615|Mechanic     |2023-12-01   |\n",
      "+-----------+--------------+---+-----------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SSN: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "\n",
      "✅ Financial Features Data:\n",
      "+-----------+------------------+---------------------+-----------------+---------------+-------------+-----------+---------------------------------------------------------------------+-------------------+----------------------+--------------------+--------------------+----------+----------------+------------------------+----------------------+---------------------+-------------------+-----------------------+--------------------------------+------------------+-------------+\n",
      "|Customer_ID|Annual_Income     |Monthly_Inhand_Salary|Num_Bank_Accounts|Num_Credit_Card|Interest_Rate|Num_of_Loan|Type_of_Loan                                                         |Delay_from_due_date|Num_of_Delayed_Payment|Changed_Credit_Limit|Num_Credit_Inquiries|Credit_Mix|Outstanding_Debt|Credit_Utilization_Ratio|Credit_History_Age    |Payment_of_Min_Amount|Total_EMI_per_month|Amount_invested_monthly|Payment_Behaviour               |Monthly_Balance   |snapshot_date|\n",
      "+-----------+------------------+---------------------+-----------------+---------------+-------------+-----------+---------------------------------------------------------------------+-------------------+----------------------+--------------------+--------------------+----------+----------------+------------------------+----------------------+---------------------+-------------------+-----------------------+--------------------------------+------------------+-------------+\n",
      "|CUS_0x1000 |30625.94          |2706.1616666666664   |6                |5              |27           |2          |Credit-Builder Loan, and Home Equity Loan                            |57                 |26                    |1.63                |11.0                |Bad       |1562.91         |30.07719135017377       |10 Years and 9 Months |Yes                  |42.941090422469365 |77.31427572208112      |High_spent_Medium_value_payments|400.36080052211616|2023-05-01   |\n",
      "|CUS_0x1009 |52312.68_         |4250.39              |6                |5              |17           |4          |Not Specified, Home Equity Loan, Credit-Builder Loan, and Payday Loan|5                  |18                    |9.73                |4.0                 |_         |202.68          |40.286996673783         |31 Years and 0 Months |Yes                  |108.36646712525564 |58.66019164829086      |High_spent_Medium_value_payments|508.01234122645366|2025-01-01   |\n",
      "|CUS_0x100b |113781.38999999998|9549.7825            |1                |4              |1            |0          |NULL                                                                 |14                 |8                     |8.34                |4.0                 |Good      |1030.2          |28.59294254083936       |15 Years and 10 Months|No                   |0.0                |617.0792665202719      |High_spent_Small_value_payments |597.8989834797281 |2024-03-01   |\n",
      "|CUS_0x1011 |58918.47          |5208.8725            |3                |3              |17           |3          |Student Loan, Credit-Builder Loan, and Debt Consolidation Loan       |27                 |13                    |14.42               |7.0                 |Standard  |473.14          |27.82995907548726       |15 Years and 10 Months|Yes                  |123.43493879634316 |383.35084463651407     |Low_spent_Medium_value_payments |294.1014665671429 |2023-11-01   |\n",
      "|CUS_0x1013 |98620.98          |7962.415000000001    |3                |3              |6            |3          |Student Loan, Debt Consolidation Loan, and Personal Loan             |12                 |9                     |1.33                |3.0                 |Good      |1233.51         |26.52486357896023       |17 Years and 10 Months|No                   |228.018083652734   |332.3337079767732      |High_spent_Medium_value_payments|485.8897083704929 |2023-12-01   |\n",
      "+-----------+------------------+---------------------+-----------------+---------------+-------------+-----------+---------------------------------------------------------------------+-------------------+----------------------+--------------------+--------------------+----------+----------------+------------------------+----------------------+---------------------+-------------------+-----------------------+--------------------------------+------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- Annual_Income: string (nullable = true)\n",
      " |-- Monthly_Inhand_Salary: double (nullable = true)\n",
      " |-- Num_Bank_Accounts: integer (nullable = true)\n",
      " |-- Num_Credit_Card: integer (nullable = true)\n",
      " |-- Interest_Rate: integer (nullable = true)\n",
      " |-- Num_of_Loan: string (nullable = true)\n",
      " |-- Type_of_Loan: string (nullable = true)\n",
      " |-- Delay_from_due_date: integer (nullable = true)\n",
      " |-- Num_of_Delayed_Payment: string (nullable = true)\n",
      " |-- Changed_Credit_Limit: string (nullable = true)\n",
      " |-- Num_Credit_Inquiries: double (nullable = true)\n",
      " |-- Credit_Mix: string (nullable = true)\n",
      " |-- Outstanding_Debt: string (nullable = true)\n",
      " |-- Credit_Utilization_Ratio: double (nullable = true)\n",
      " |-- Credit_History_Age: string (nullable = true)\n",
      " |-- Payment_of_Min_Amount: string (nullable = true)\n",
      " |-- Total_EMI_per_month: double (nullable = true)\n",
      " |-- Amount_invested_monthly: string (nullable = true)\n",
      " |-- Payment_Behaviour: string (nullable = true)\n",
      " |-- Monthly_Balance: string (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "\n",
      "✅ Clickstream Features Data:\n",
      "+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----------+-------------+\n",
      "|fe_1|fe_2|fe_3|fe_4|fe_5|fe_6|fe_7|fe_8|fe_9|fe_10|fe_11|fe_12|fe_13|fe_14|fe_15|fe_16|fe_17|fe_18|fe_19|fe_20|Customer_ID|snapshot_date|\n",
      "+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----------+-------------+\n",
      "|63  |118 |80  |121 |55  |193 |111 |112 |-101|83   |164  |105  |-16  |-81  |-126 |114  |35   |85   |-73  |76   |CUS_0x1037 |2023-01-01   |\n",
      "|-108|182 |123 |4   |-56 |27  |25  |-6  |284 |222  |203  |190  |-14  |-96  |200  |35   |130  |94   |111  |75   |CUS_0x1069 |2023-01-01   |\n",
      "|-13 |8   |87  |166 |214 |-98 |215 |152 |129 |139  |14   |203  |26   |86   |171  |125  |-130 |354  |17   |302  |CUS_0x114a |2023-01-01   |\n",
      "|-85 |45  |200 |89  |128 |54  |76  |51  |61  |139  |6    |197  |172  |96   |174  |163  |37   |207  |180  |118  |CUS_0x1184 |2023-01-01   |\n",
      "|55  |120 |226 |-86 |253 |97  |107 |68  |103 |126  |34   |12   |76   |43   |183  |159  |-26  |104  |118  |184  |CUS_0x1297 |2023-01-01   |\n",
      "+----+----+----+----+----+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- fe_1: integer (nullable = true)\n",
      " |-- fe_2: integer (nullable = true)\n",
      " |-- fe_3: integer (nullable = true)\n",
      " |-- fe_4: integer (nullable = true)\n",
      " |-- fe_5: integer (nullable = true)\n",
      " |-- fe_6: integer (nullable = true)\n",
      " |-- fe_7: integer (nullable = true)\n",
      " |-- fe_8: integer (nullable = true)\n",
      " |-- fe_9: integer (nullable = true)\n",
      " |-- fe_10: integer (nullable = true)\n",
      " |-- fe_11: integer (nullable = true)\n",
      " |-- fe_12: integer (nullable = true)\n",
      " |-- fe_13: integer (nullable = true)\n",
      " |-- fe_14: integer (nullable = true)\n",
      " |-- fe_15: integer (nullable = true)\n",
      " |-- fe_16: integer (nullable = true)\n",
      " |-- fe_17: integer (nullable = true)\n",
      " |-- fe_18: integer (nullable = true)\n",
      " |-- fe_19: integer (nullable = true)\n",
      " |-- fe_20: integer (nullable = true)\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- snapshot_date: date (nullable = true)\n",
      "\n",
      "\n",
      "Row Counts:\n",
      "  LMS: 137500\n",
      "  ATTR: 12500\n",
      "  FIN: 12500\n",
      "  CLICK: 215376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1️⃣ Read lms_loan_daily.csv\n",
    "# ----------------------------\n",
    "lms_path = \"data/lms_loan_daily.csv\"\n",
    "df_lms = spark.read.csv(lms_path, header=True, inferSchema=True)\n",
    "print(\"✅ LMS Loan Daily Data:\")\n",
    "df_lms.show(5, truncate=False)\n",
    "df_lms.printSchema()\n",
    "\n",
    "# ----------------------------\n",
    "# 2️⃣ Read features_attributes.csv\n",
    "# ----------------------------\n",
    "attr_path = \"data/features_attributes.csv\"\n",
    "df_attr = spark.read.csv(attr_path, header=True, inferSchema=True)\n",
    "print(\"\\n✅ Customer Attributes Data:\")\n",
    "df_attr.show(5, truncate=False)\n",
    "df_attr.printSchema()\n",
    "\n",
    "# ----------------------------\n",
    "# 3️⃣ Read features_financials.csv\n",
    "# ----------------------------\n",
    "fin_path = \"data/features_financials.csv\"\n",
    "df_fin = spark.read.csv(fin_path, header=True, inferSchema=True)\n",
    "print(\"\\n✅ Financial Features Data:\")\n",
    "df_fin.show(5, truncate=False)\n",
    "df_fin.printSchema()\n",
    "\n",
    "# ----------------------------\n",
    "# 4️⃣ Read feature_clickstream.csv\n",
    "# ----------------------------\n",
    "click_path = \"data/feature_clickstream.csv\"\n",
    "df_click = spark.read.csv(click_path, header=True, inferSchema=True)\n",
    "print(\"\\n✅ Clickstream Features Data:\")\n",
    "df_click.show(5, truncate=False)\n",
    "df_click.printSchema()\n",
    "\n",
    "# ----------------------------\n",
    "# Optional: Count rows for a quick sanity check\n",
    "# ----------------------------\n",
    "print(f\"\"\"\n",
    "Row Counts:\n",
    "  LMS: {df_lms.count()}\n",
    "  ATTR: {df_attr.count()}\n",
    "  FIN: {df_fin.count()}\n",
    "  CLICK: {df_click.count()}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6494753-4647-44a4-82b4-3325e971580f",
   "metadata": {},
   "source": [
    "## Check df_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf4bbbd-d934-4356-b8b4-3832767b504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+---+-----------+-------------+-------------+\n",
      "|Customer_ID|             Name|Age|        SSN|   Occupation|snapshot_date|\n",
      "+-----------+-----------------+---+-----------+-------------+-------------+\n",
      "| CUS_0x1000|   Alistair Barrf| 18|913-74-1218|       Lawyer|   2023-05-01|\n",
      "| CUS_0x1009|           Arunah| 26|063-67-6938|     Mechanic|   2025-01-01|\n",
      "| CUS_0x100b|         Shirboni| 19|  #F%$D@*&8|Media_Manager|   2024-03-01|\n",
      "| CUS_0x1011|        Schneyerh| 44|793-05-8223|       Doctor|   2023-11-01|\n",
      "| CUS_0x1013|         Cameront| 44|930-49-9615|     Mechanic|   2023-12-01|\n",
      "| CUS_0x1015|          Holtono| 27|810-97-7024|   Journalist|   2023-08-01|\n",
      "| CUS_0x1018|      Felsenthalq| 15|731-19-8119|   Accountant|   2023-11-01|\n",
      "| CUS_0x1026|          Josephv| 52|500-62-9044|      Manager|   2023-10-01|\n",
      "| CUS_0x102d| Neil Chatterjeex| 31|692-71-7552| Entrepreneur|   2024-01-01|\n",
      "| CUS_0x102e|            Rhysn| 26|  #F%$D@*&8|    Scientist|   2024-04-01|\n",
      "| CUS_0x1032|           Wahbap|40_|620-58-8045|       Lawyer|   2023-08-01|\n",
      "| CUS_0x1037|         Matthewm| 45|230-22-9583|   Accountant|   2023-01-01|\n",
      "| CUS_0x1038|              B.h| 28|355-00-7832|    Architect|   2024-10-01|\n",
      "| CUS_0x103e|       Tim Kellyf| 40|155-72-8070|    Scientist|   2024-12-01|\n",
      "| CUS_0x1041|Jonathan Stempela| 15|675-80-2033|      Teacher|   2023-11-01|\n",
      "| CUS_0x1044|    Maki Shirakip| 44|  #F%$D@*&8|      _______|   2023-06-01|\n",
      "| CUS_0x1048|   Janet McGurtyg| 27|808-81-2470|   Accountant|   2024-02-01|\n",
      "| CUS_0x104a|            Leahk| 37|  #F%$D@*&8|     Mechanic|   2023-12-01|\n",
      "| CUS_0x104e|         Kentaros| 50|837-93-5062|      Teacher|   2023-06-01|\n",
      "| CUS_0x104f|            Markm| 20|264-84-8069|      _______|   2024-10-01|\n",
      "+-----------+-----------------+---+-----------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_attr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e46404-f5c9-4413-88f2-b5f626a26bf9",
   "metadata": {},
   "source": [
    "A few problematic inconsistencies are seen. Age is in string and some have an underscore after the value. Occupation has empty values that are filled with underscores. SSN has problematic values that are == #F%$D@*&8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32410606-25cf-42bc-a779-b3177a7d23a8",
   "metadata": {},
   "source": [
    "### Fix SSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "297a4873-03a7-4a06-9d34-cb6c0ec6d309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr.filter(F.col(\"SSN\") == \"#F%$D@*&8\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b0b3721-6b8b-4419-a88b-b852ade80eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr = df_attr.withColumn(\n",
    "    \"SSN\",\n",
    "    F.when(F.col(\"SSN\") == \"#F%$D@*&8\", \"000-00-0000\")\n",
    "     .otherwise(F.col(\"SSN\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c67fc27-80f5-4014-9e35-bde33ca3e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+---+-----------+-------------+-------------+\n",
      "|Customer_ID|             Name|Age|        SSN|   Occupation|snapshot_date|\n",
      "+-----------+-----------------+---+-----------+-------------+-------------+\n",
      "| CUS_0x1000|   Alistair Barrf| 18|913-74-1218|       Lawyer|   2023-05-01|\n",
      "| CUS_0x1009|           Arunah| 26|063-67-6938|     Mechanic|   2025-01-01|\n",
      "| CUS_0x100b|         Shirboni| 19|000-00-0000|Media_Manager|   2024-03-01|\n",
      "| CUS_0x1011|        Schneyerh| 44|793-05-8223|       Doctor|   2023-11-01|\n",
      "| CUS_0x1013|         Cameront| 44|930-49-9615|     Mechanic|   2023-12-01|\n",
      "| CUS_0x1015|          Holtono| 27|810-97-7024|   Journalist|   2023-08-01|\n",
      "| CUS_0x1018|      Felsenthalq| 15|731-19-8119|   Accountant|   2023-11-01|\n",
      "| CUS_0x1026|          Josephv| 52|500-62-9044|      Manager|   2023-10-01|\n",
      "| CUS_0x102d| Neil Chatterjeex| 31|692-71-7552| Entrepreneur|   2024-01-01|\n",
      "| CUS_0x102e|            Rhysn| 26|000-00-0000|    Scientist|   2024-04-01|\n",
      "| CUS_0x1032|           Wahbap|40_|620-58-8045|       Lawyer|   2023-08-01|\n",
      "| CUS_0x1037|         Matthewm| 45|230-22-9583|   Accountant|   2023-01-01|\n",
      "| CUS_0x1038|              B.h| 28|355-00-7832|    Architect|   2024-10-01|\n",
      "| CUS_0x103e|       Tim Kellyf| 40|155-72-8070|    Scientist|   2024-12-01|\n",
      "| CUS_0x1041|Jonathan Stempela| 15|675-80-2033|      Teacher|   2023-11-01|\n",
      "| CUS_0x1044|    Maki Shirakip| 44|000-00-0000|      _______|   2023-06-01|\n",
      "| CUS_0x1048|   Janet McGurtyg| 27|808-81-2470|   Accountant|   2024-02-01|\n",
      "| CUS_0x104a|            Leahk| 37|000-00-0000|     Mechanic|   2023-12-01|\n",
      "| CUS_0x104e|         Kentaros| 50|837-93-5062|      Teacher|   2023-06-01|\n",
      "| CUS_0x104f|            Markm| 20|264-84-8069|      _______|   2024-10-01|\n",
      "+-----------+-----------------+---+-----------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_attr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de8c1e-6829-42ad-b17b-c539217792c1",
   "metadata": {},
   "source": [
    "### Fix Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4b08d2f4-03d6-4e97-a47a-fddfb8d7ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Occupation   |\n",
      "+-------------+\n",
      "|Accountant   |\n",
      "|Architect    |\n",
      "|Developer    |\n",
      "|Doctor       |\n",
      "|Engineer     |\n",
      "|Entrepreneur |\n",
      "|Journalist   |\n",
      "|Lawyer       |\n",
      "|Manager      |\n",
      "|Mechanic     |\n",
      "|Media_Manager|\n",
      "|Musician     |\n",
      "|Scientist    |\n",
      "|Teacher      |\n",
      "|Writer       |\n",
      "|_______      |\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_attr.select(\"Occupation\") \\\n",
    "    .distinct() \\\n",
    "    .orderBy(\"Occupation\") \\\n",
    "    .show(100, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d5ca0299-78eb-4865-9479-200df5c9b2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr.filter(F.col(\"Occupation\") == \"_______\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "57e58f59-1976-48a6-9ee7-e922b60cce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr = df_attr.withColumn(\n",
    "    \"Occupation\",\n",
    "    F.when(F.col(\"Occupation\") == \"_______\", \"Unemployed\")\n",
    "     .otherwise(F.col(\"Occupation\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b32499e7-66f2-4206-b231-7919e772eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Occupation   |\n",
      "+-------------+\n",
      "|Accountant   |\n",
      "|Architect    |\n",
      "|Developer    |\n",
      "|Doctor       |\n",
      "|Engineer     |\n",
      "|Entrepreneur |\n",
      "|Journalist   |\n",
      "|Lawyer       |\n",
      "|Manager      |\n",
      "|Mechanic     |\n",
      "|Media_Manager|\n",
      "|Musician     |\n",
      "|Scientist    |\n",
      "|Teacher      |\n",
      "|Unemployed   |\n",
      "|Writer       |\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_attr.select(\"Occupation\") \\\n",
    "    .distinct() \\\n",
    "    .orderBy(\"Occupation\") \\\n",
    "    .show(100, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fabaa7-8efd-4ae7-a94a-1080f4944152",
   "metadata": {},
   "source": [
    "### Fix Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce0a71b-31ff-4b36-82a1-3dfb962a8653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------+-----+\n",
      "|Customer_ID|Name                  |Age  |\n",
      "+-----------+----------------------+-----+\n",
      "|CUS_0x1032 |Wahbap                |40_  |\n",
      "|CUS_0x1057 |David Sheppardv       |46_  |\n",
      "|CUS_0x10e7 |Carewj                |3843_|\n",
      "|CUS_0x10ee |Hudsonb               |30_  |\n",
      "|CUS_0x111c |Deepaa                |24_  |\n",
      "|CUS_0x1135 |Baertleinc            |22_  |\n",
      "|CUS_0x1139 |Copleyp               |32_  |\n",
      "|CUS_0x11ac |Liana B.v             |26_  |\n",
      "|CUS_0x1204 |Lashg                 |46_  |\n",
      "|CUS_0x1288 |Taylorq               |34_  |\n",
      "|CUS_0x13a8 |Baileyz               |41_  |\n",
      "|CUS_0x13c2 |Menonv                |40_  |\n",
      "|CUS_0x13e4 |Edward Krudyl         |1248_|\n",
      "|CUS_0x1430 |Chiango               |30_  |\n",
      "|CUS_0x14a3 |Prustyx               |-500 |\n",
      "|CUS_0x14f4 |Richardc              |23_  |\n",
      "|CUS_0x14f5 |Richard Leongd        |41_  |\n",
      "|CUS_0x157d |Thompsonf             |24_  |\n",
      "|CUS_0x1600 |Megan Daviesb         |30_  |\n",
      "|CUS_0x1604 |Sam Forgioneb         |43_  |\n",
      "|CUS_0x163c |Julien Toyera         |32_  |\n",
      "|CUS_0x1647 |Caroline Valetkevitchb|19_  |\n",
      "|CUS_0x16a6 |Schnurrz              |26_  |\n",
      "|CUS_0x16f5 |Annj                  |53_  |\n",
      "|CUS_0x17d7 |Polansekz             |41_  |\n",
      "|CUS_0x1821 |Piersonm              |18_  |\n",
      "|CUS_0x183d |Whiteb                |15_  |\n",
      "|CUS_0x188f |Johant                |55_  |\n",
      "|CUS_0x1899 |Pineaun               |43_  |\n",
      "|CUS_0x1902 |Melindai              |43_  |\n",
      "|CUS_0x191f |Ryanc                 |50_  |\n",
      "|CUS_0x1948 |Jonathan Cablew       |-500 |\n",
      "|CUS_0x195b |Rodrigo Camposl       |42_  |\n",
      "|CUS_0x1968 |Cezaryq               |16_  |\n",
      "|CUS_0x1999 |Silviob               |32_  |\n",
      "|CUS_0x19a5 |Rickp                 |27_  |\n",
      "|CUS_0x19a8 |Victoriav             |-500 |\n",
      "|CUS_0x19c9 |Cableo                |31_  |\n",
      "|CUS_0x19d4 |Mollenkampj           |32_  |\n",
      "|CUS_0x1a53 |Petersono             |38_  |\n",
      "|CUS_0x1a96 |Sinead Carewi         |50_  |\n",
      "|CUS_0x1b1a |Michaeli              |8669_|\n",
      "|CUS_0x1bfd |Dougs                 |40_  |\n",
      "|CUS_0x1c2a |Pault                 |45_  |\n",
      "|CUS_0x1c3a |Finnt                 |32_  |\n",
      "|CUS_0x1c3b |Alexei Anishchukq     |39_  |\n",
      "|CUS_0x1c89 |Tanyab                |17_  |\n",
      "|CUS_0x1cb8 |Antoniolil            |53_  |\n",
      "|CUS_0x1d00 |Herbert Lashd         |44_  |\n",
      "|CUS_0x1d08 |Skariachanh           |-500 |\n",
      "+-----------+----------------------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_attr.filter(~F.col(\"Age\").rlike(\"^[0-9]+$\")).select(\"Customer_ID\", \"Name\", \"Age\").show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b08d30-e4ed-455c-af4c-696ebaa58b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| Age|\n",
      "+----+\n",
      "|-500|\n",
      "|1004|\n",
      "|1022|\n",
      "|1066|\n",
      "|1087|\n",
      "|1094|\n",
      "|1149|\n",
      "|1203|\n",
      "|1220|\n",
      "|1265|\n",
      "|1388|\n",
      "|1418|\n",
      "|1520|\n",
      "|1683|\n",
      "| 169|\n",
      "|1733|\n",
      "|1792|\n",
      "|1810|\n",
      "|1814|\n",
      "|1990|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_attr.filter((F.col(\"Age\") < 0) | (F.col(\"Age\") > 100)) \\\n",
    "    .select(\"Age\") \\\n",
    "    .distinct() \\\n",
    "    .orderBy(\"Age\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eac65a73-66bd-4744-ad5c-23e20847c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr = df_attr.withColumn(\n",
    "    \"Age\",\n",
    "    F.when((F.col(\"Age\") >= 0) & (F.col(\"Age\") <= 100), F.col(\"Age\"))\n",
    "     .otherwise(None)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "770b0224-a0dc-48ce-887a-588e4cb75b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Age|\n",
      "+---+\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_attr.filter((F.col(\"Age\") < 0) | (F.col(\"Age\") > 100)) \\\n",
    "    .select(\"Age\") \\\n",
    "    .distinct() \\\n",
    "    .orderBy(\"Age\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b8322-95ba-4aa7-8cad-a1ecaf9b81b8",
   "metadata": {},
   "source": [
    "Set age to None if problematic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f054207-7ee3-4042-862a-6049058d3dfb",
   "metadata": {},
   "source": [
    "## DF fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb099e-3f3e-482c-ae25-d7004a1585a9",
   "metadata": {},
   "source": [
    "### Clean all numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "108ea72a-2fa5-4672-b8e1-c99da11439f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_column(df, column_name):\n",
    "    \"\"\"\n",
    "    Cleans a numeric column in a PySpark DataFrame:\n",
    "    1. Removes stray underscores from numeric values.\n",
    "    2. Casts the column to FloatType.\n",
    "    3. Uses IQR to detect outliers.\n",
    "    4. Replaces outliers with None.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Input PySpark DataFrame\n",
    "        column_name (str): Name of the numeric column to clean\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Cleaned DataFrame with outliers replaced by None\n",
    "    \"\"\"\n",
    "    # Remove underscores and cast to float\n",
    "    dtype_lookup = dict(df.dtypes).get(column_name)\n",
    "    if dtype_lookup == \"string\":\n",
    "        df = df.withColumn(column_name, F.regexp_replace(F.col(column_name), \"_\", \"\"))\n",
    "\n",
    "    df = df.withColumn(column_name, F.col(column_name).cast(FloatType()))\n",
    "\n",
    "    # Compute IQR boundaries\n",
    "    q1, q3 = df.approxQuantile(column_name, [0.25, 0.75], 0.01)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "\n",
    "    # Replace outliers with iqr ranges\n",
    "    df = df.withColumn(\n",
    "        column_name,\n",
    "        F.when((F.col(column_name) >= lower) & (F.col(column_name) <= upper),\n",
    "               F.col(column_name))\n",
    "         .otherwise(F.lit(None))\n",
    "    )\n",
    "\n",
    "    print(f\"[CLEAN] Column '{column_name}' cleaned. IQR bounds: ({lower:.2f}, {upper:.2f})\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98c54af2-bced-471b-9a54-90552bb88d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = spark.read.csv(fin_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8d40881-8b2e-40bb-8fe4-5b0dfbb858f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Customer_ID', 'string'),\n",
       " ('Annual_Income', 'string'),\n",
       " ('Monthly_Inhand_Salary', 'double'),\n",
       " ('Num_Bank_Accounts', 'int'),\n",
       " ('Num_Credit_Card', 'int'),\n",
       " ('Interest_Rate', 'int'),\n",
       " ('Num_of_Loan', 'string'),\n",
       " ('Type_of_Loan', 'string'),\n",
       " ('Delay_from_due_date', 'int'),\n",
       " ('Num_of_Delayed_Payment', 'string'),\n",
       " ('Changed_Credit_Limit', 'string'),\n",
       " ('Num_Credit_Inquiries', 'double'),\n",
       " ('Credit_Mix', 'string'),\n",
       " ('Outstanding_Debt', 'string'),\n",
       " ('Credit_Utilization_Ratio', 'double'),\n",
       " ('Credit_History_Age', 'string'),\n",
       " ('Payment_of_Min_Amount', 'string'),\n",
       " ('Total_EMI_per_month', 'double'),\n",
       " ('Amount_invested_monthly', 'string'),\n",
       " ('Payment_Behaviour', 'string'),\n",
       " ('Monthly_Balance', 'string'),\n",
       " ('snapshot_date', 'date')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a84e90a-0496-48ee-a5f4-3023c56ac0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLEAN] Column 'Annual_Income' cleaned. IQR bounds: (-59626.93, 150522.66)\n",
      "[CLEAN] Column 'Monthly_Inhand_Salary' cleaned. IQR bounds: (-4820.54, 12303.13)\n",
      "[CLEAN] Column 'Num_Bank_Accounts' cleaned. IQR bounds: (-3.00, 13.00)\n",
      "[CLEAN] Column 'Num_Credit_Card' cleaned. IQR bounds: (-0.50, 11.50)\n",
      "[CLEAN] Column 'Interest_Rate' cleaned. IQR bounds: (-12.50, 39.50)\n",
      "[CLEAN] Column 'Num_of_Loan' cleaned. IQR bounds: (-5.00, 11.00)\n",
      "[CLEAN] Column 'Delay_from_due_date' cleaned. IQR bounds: (-17.00, 55.00)\n",
      "[CLEAN] Column 'Num_of_Delayed_Payment' cleaned. IQR bounds: (-4.50, 31.50)\n",
      "[CLEAN] Column 'Changed_Credit_Limit' cleaned. IQR bounds: (-8.52, 28.40)\n",
      "[CLEAN] Column 'Num_Credit_Inquiries' cleaned. IQR bounds: (-7.50, 20.50)\n",
      "[CLEAN] Column 'Outstanding_Debt' cleaned. IQR bounds: (-1474.93, 3928.24)\n",
      "[CLEAN] Column 'Credit_Utilization_Ratio' cleaned. IQR bounds: (14.98, 49.45)\n",
      "[CLEAN] Column 'Total_EMI_per_month' cleaned. IQR bounds: (-173.28, 369.76)\n",
      "[CLEAN] Column 'Amount_invested_monthly' cleaned. IQR bounds: (-201.21, 527.63)\n",
      "[CLEAN] Column 'Monthly_Balance' cleaned. IQR bounds: (-32.28, 767.32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_fin = clean_numeric_column(df_fin, \"Annual_Income\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Monthly_Inhand_Salary\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Num_Bank_Accounts\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Num_Credit_Card\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Interest_Rate\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Num_of_Loan\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Delay_from_due_date\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Num_of_Delayed_Payment\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Changed_Credit_Limit\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Num_Credit_Inquiries\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Outstanding_Debt\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Credit_Utilization_Ratio\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Total_EMI_per_month\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Amount_invested_monthly\")\n",
    "df_fin = clean_numeric_column(df_fin, \"Monthly_Balance\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44cc210-31c6-4c6f-8a9f-53aa69374915",
   "metadata": {},
   "source": [
    "### Change credit history age to num of months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8932d96a-8eca-4fb0-b469-c59bcac34ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|Customer_ID|Credit_History_Age|\n",
      "+-----------+------------------+\n",
      "|CUS_0x1000 |129               |\n",
      "|CUS_0x1009 |372               |\n",
      "|CUS_0x100b |190               |\n",
      "|CUS_0x1011 |190               |\n",
      "|CUS_0x1013 |214               |\n",
      "|CUS_0x1015 |257               |\n",
      "|CUS_0x1018 |171               |\n",
      "|CUS_0x1026 |248               |\n",
      "|CUS_0x102d |363               |\n",
      "|CUS_0x102e |274               |\n",
      "+-----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fin = df_fin.withColumn(\n",
    "    \"Credit_History_Age\",\n",
    "    F.regexp_replace(F.col(\"Credit_History_Age\"), \"_\", \"\")  # remove underscores if any\n",
    ")\n",
    "\n",
    "df_fin = df_fin.withColumn(\n",
    "    \"Years\",\n",
    "    F.regexp_extract(F.col(\"Credit_History_Age\"), r\"(\\d+)\\s+Years\", 1).cast(\"int\")\n",
    ").withColumn(\n",
    "    \"Months\",\n",
    "    F.regexp_extract(F.col(\"Credit_History_Age\"), r\"(\\d+)\\s+Months\", 1).cast(\"int\")\n",
    ")\n",
    "\n",
    "df_fin = df_fin.withColumn(\n",
    "    \"Credit_History_Age_Months\",\n",
    "    (F.col(\"Years\") * 12 + F.col(\"Months\"))\n",
    ")\n",
    "\n",
    "# Drop the old columns\n",
    "df_fin = df_fin.drop(\"Years\", \"Months\", \"Credit_History_Age\")\n",
    "\n",
    "# rename for simplicity\n",
    "df_fin = df_fin.withColumnRenamed(\"Credit_History_Age_Months\", \"Credit_History_Age\")\n",
    "\n",
    "df_fin.select(\"Customer_ID\", \"Credit_History_Age\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3baf21-314d-4caa-8f14-eb69cc290a0f",
   "metadata": {},
   "source": [
    "### Fix Categorical variables: (Payment_of_Min_Amount, Payment_behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be248b4e-b8fd-4577-a33a-a82fcff2d43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|Payment_of_Min_Amount|\n",
      "+---------------------+\n",
      "|                   No|\n",
      "|                  Yes|\n",
      "|                 NULL|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fin = df_fin.withColumn(\n",
    "    \"Payment_of_Min_Amount\",\n",
    "    F.trim(F.lower(F.col(\"Payment_of_Min_Amount\")))  # normalize case\n",
    ")\n",
    "\n",
    "df_fin = df_fin.withColumn(\n",
    "    \"Payment_of_Min_Amount\",\n",
    "    F.when(F.col(\"Payment_of_Min_Amount\").isin(\"yes\", \"y\"), \"Yes\")\n",
    "     .when(F.col(\"Payment_of_Min_Amount\").isin(\"no\", \"n\"), \"No\")\n",
    "     .when(F.col(\"Payment_of_Min_Amount\").isin(\"nm\", \"not mentioned\", \"na\", \"none\"), None)\n",
    "     .otherwise(F.col(\"Payment_of_Min_Amount\"))  # keep valid ones\n",
    ")\n",
    "\n",
    "df_fin.select(\"Payment_of_Min_Amount\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7fc47d8-afaf-4572-a889-4daedae17569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = df_fin.withColumn(\n",
    "    \"Payment_Behaviour\",\n",
    "    F.when(F.col(\"Payment_Behaviour\") == \"!@9#%8\", \"Unknown\")\n",
    "     .otherwise(F.col(\"Payment_Behaviour\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b990a02-dd91-45be-abc2-8d70a8abf7e2",
   "metadata": {},
   "source": [
    "## Load all silver parquet files (EDA for gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "19f4a239-39ed-4b53-848b-0adec5de459c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Customer_ID: string, Name: string, Age: int, SSN: string, Occupation: string, snapshot_date: date]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_files = glob.glob(os.path.join(\"datamart/silver/attributes\", \"*.parquet\"))\n",
    "\n",
    "df_attr = spark.read.parquet(*parquet_files)\n",
    "df_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d73586ff-11af-4a00-9bba-18ab97a70915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e66480b5-80d4-45f4-a425-338a48b4f73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+---+---+----------+-------------+\n",
      "|Customer_ID|Name|Age|SSN|Occupation|snapshot_date|\n",
      "+-----------+----+---+---+----------+-------------+\n",
      "|          0|   0|319|  0|         0|            0|\n",
      "+-----------+----+---+---+----------+-------------+\n",
      "\n",
      "+-----------+------------+-------------+\n",
      "|Customer_ID|  Occupation|snapshot_date|\n",
      "+-----------+------------+-------------+\n",
      "| CUS_0x10ac|   Developer|   2024-08-01|\n",
      "| CUS_0x10c5|  Unemployed|   2024-08-01|\n",
      "| CUS_0x1145|     Teacher|   2024-08-01|\n",
      "| CUS_0x11ac|  Journalist|   2024-08-01|\n",
      "| CUS_0x122c|Entrepreneur|   2024-08-01|\n",
      "| CUS_0x1274|   Scientist|   2024-08-01|\n",
      "| CUS_0x1288|      Doctor|   2024-08-01|\n",
      "| CUS_0x12cc|   Developer|   2024-08-01|\n",
      "| CUS_0x1338|  Unemployed|   2024-08-01|\n",
      "| CUS_0x1370|      Writer|   2024-08-01|\n",
      "| CUS_0x1378|    Mechanic|   2024-08-01|\n",
      "| CUS_0x139b|   Scientist|   2024-08-01|\n",
      "| CUS_0x13a9|     Manager|   2024-08-01|\n",
      "| CUS_0x13ce|     Manager|   2024-08-01|\n",
      "| CUS_0x147a|      Writer|   2024-08-01|\n",
      "| CUS_0x1510|      Doctor|   2024-08-01|\n",
      "| CUS_0x1572|    Engineer|   2024-08-01|\n",
      "| CUS_0x159b|   Architect|   2024-08-01|\n",
      "| CUS_0x15f1|  Unemployed|   2024-08-01|\n",
      "| CUS_0x1621|      Writer|   2024-08-01|\n",
      "+-----------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "\n",
    "df_attr.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c) \n",
    "    for c in df_attr.columns\n",
    "]).show()\n",
    "\n",
    "\n",
    "# drop age, name, ssn,\n",
    "df_attr = df_attr.drop(\"Age\", \"Name\", \"SSN\")  # drop columns with too many nulls\n",
    "df_attr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "683d7a6a-3d51-4d10-85d0-fb04dc2359b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNABLE_TO_INFER_SCHEMA] Unable to infer schema for Parquet. It must be specified manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m parquet_files = glob.glob(os.path.join(\u001b[33m\"\u001b[39m\u001b[33mdatamart/silver/fin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m*.parquet\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_fin = \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparquet_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m pd_df = df_fin.limit(\u001b[32m5\u001b[39m).toPandas()\n\u001b[32m      5\u001b[39m pd_df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pyspark/sql/readwriter.py:544\u001b[39m, in \u001b[36mDataFrameReader.parquet\u001b[39m\u001b[34m(self, *paths, **options)\u001b[39m\n\u001b[32m    533\u001b[39m int96RebaseMode = options.get(\u001b[33m\"\u001b[39m\u001b[33mint96RebaseMode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    534\u001b[39m \u001b[38;5;28mself\u001b[39m._set_opts(\n\u001b[32m    535\u001b[39m     mergeSchema=mergeSchema,\n\u001b[32m    536\u001b[39m     pathGlobFilter=pathGlobFilter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m     int96RebaseMode=int96RebaseMode,\n\u001b[32m    542\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m544\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_spark\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [UNABLE_TO_INFER_SCHEMA] Unable to infer schema for Parquet. It must be specified manually."
     ]
    }
   ],
   "source": [
    "parquet_files = glob.glob(os.path.join(\"datamart/silver/fin\", \"*.parquet\"))\n",
    "\n",
    "df_fin = spark.read.parquet(*parquet_files)\n",
    "pd_df = df_fin.limit(5).toPandas()\n",
    "pd_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f2e2f61-d1b4-47cd-8321-823a4df49ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove type_of_loan\n",
    "\n",
    "df_fin = df_fin.drop(\"Type_of_Loan\")  # drop useless col\n",
    "\n",
    "df_fin.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "840ec7a0-8a2d-436b-abcc-5e708691ec36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             0\n",
      "Customer_ID                  0\n",
      "Annual_Income              371\n",
      "Monthly_Inhand_Salary      298\n",
      "Num_Bank_Accounts          168\n",
      "Num_Credit_Card            296\n",
      "Interest_Rate              270\n",
      "Num_of_Loan                582\n",
      "Delay_from_due_date        522\n",
      "Num_of_Delayed_Payment     105\n",
      "Changed_Credit_Limit       429\n",
      "Num_Credit_Inquiries       202\n",
      "Credit_Mix                   0\n",
      "Outstanding_Debt           743\n",
      "Credit_Utilization_Ratio     0\n",
      "Payment_of_Min_Amount     1438\n",
      "Total_EMI_per_month        995\n",
      "Amount_invested_monthly   1406\n",
      "Payment_Behaviour            0\n",
      "Monthly_Balance           1029\n",
      "snapshot_date                0\n",
      "Credit_History_Age           0\n"
     ]
    }
   ],
   "source": [
    "null_counts = df_fin.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c)\n",
    "    for c in df_fin.columns\n",
    "]).toPandas()\n",
    "\n",
    "print(null_counts.T)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35546bc6-6536-4f26-8368-8fa28d2f5c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "57ff6701-936f-485c-b9b7-5853e0de20c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          % Null\n",
      "Customer_ID                0.000\n",
      "Annual_Income              2.968\n",
      "Monthly_Inhand_Salary      2.384\n",
      "Num_Bank_Accounts          1.344\n",
      "Num_Credit_Card            2.368\n",
      "Interest_Rate              2.160\n",
      "Num_of_Loan                4.656\n",
      "Delay_from_due_date        4.176\n",
      "Num_of_Delayed_Payment     0.840\n",
      "Changed_Credit_Limit       3.432\n",
      "Num_Credit_Inquiries       1.616\n",
      "Credit_Mix                 0.000\n",
      "Outstanding_Debt           5.944\n",
      "Credit_Utilization_Ratio   0.000\n",
      "Payment_of_Min_Amount     11.504\n",
      "Total_EMI_per_month        7.960\n",
      "Amount_invested_monthly   11.248\n",
      "Payment_Behaviour          0.000\n",
      "Monthly_Balance            8.232\n",
      "snapshot_date              0.000\n",
      "Credit_History_Age         0.000\n"
     ]
    }
   ],
   "source": [
    "rows = df_fin.count()\n",
    "nulls = df_fin.select([\n",
    "    (F.count(F.when(F.col(c).isNull(), c)) / rows * 100).alias(c)\n",
    "    for c in df_fin.columns\n",
    "])\n",
    "\n",
    "# Convert to Pandas and transpose for readability\n",
    "nulls_pdf = nulls.toPandas().T\n",
    "nulls_pdf.columns = ['% Null']\n",
    "print(nulls_pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e60eef-922d-4c94-9d4e-9ac3728a98ca",
   "metadata": {},
   "source": [
    "There is a significant portion of Null values inside df_fin. We will drop those with more than 5% null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05a74c5e-c7ce-4664-aa77-369f6204c007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['Type_of_Loan', 'Outstanding_Debt', 'Payment_of_Min_Amount', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance']\n"
     ]
    }
   ],
   "source": [
    "# Calculate null percentages\n",
    "rows = df_fin.count()\n",
    "nulls = df_fin.select([\n",
    "    (F.count(F.when(F.col(c).isNull(), c)) / rows * 100).alias(c)\n",
    "    for c in df_fin.columns\n",
    "])\n",
    "\n",
    "# Collect null percentages into a dict\n",
    "nulls_dict = nulls.collect()[0].asDict()\n",
    "\n",
    "# Get columns to drop\n",
    "cols_to_drop = [col for col, pct in nulls_dict.items() if pct > 5]\n",
    "\n",
    "# Drop columns from DataFrame\n",
    "df_fin = df_fin.drop(*cols_to_drop)\n",
    "\n",
    "print(\"Dropped columns:\", cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d21bb3-65d1-456a-9dda-f7fa279a9f28",
   "metadata": {},
   "source": [
    "Since only a handful of rows are left that are null we will just drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7f930b01-b193-4a02-b7a8-88ebda9021a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = df_fin.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "064e8351-9683-433c-9fca-8aaa7f23b08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          % Null\n",
      "Customer_ID                  0.0\n",
      "Annual_Income                0.0\n",
      "Monthly_Inhand_Salary        0.0\n",
      "Num_Bank_Accounts            0.0\n",
      "Num_Credit_Card              0.0\n",
      "Interest_Rate                0.0\n",
      "Num_of_Loan                  0.0\n",
      "Delay_from_due_date          0.0\n",
      "Num_of_Delayed_Payment       0.0\n",
      "Changed_Credit_Limit         0.0\n",
      "Num_Credit_Inquiries         0.0\n",
      "Credit_Mix                   0.0\n",
      "Credit_Utilization_Ratio     0.0\n",
      "Payment_Behaviour            0.0\n",
      "snapshot_date                0.0\n",
      "Credit_History_Age           0.0\n"
     ]
    }
   ],
   "source": [
    "rows = df_fin.count()\n",
    "nulls = df_fin.select([\n",
    "    (F.count(F.when(F.col(c).isNull(), c)) / rows * 100).alias(c)\n",
    "    for c in df_fin.columns\n",
    "])\n",
    "\n",
    "# Convert to Pandas and transpose for readability\n",
    "nulls_pdf = nulls.toPandas().T\n",
    "nulls_pdf.columns = ['% Null']\n",
    "print(nulls_pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ecf2d-4e49-4689-9e45-db8f11c3e17e",
   "metadata": {},
   "source": [
    "no more null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e0232c2c-b223-49d7-8edb-4cc389accf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215376"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickstream_directory = \"datamart/bronze/clickstream/\"\n",
    "df_click = spark.read.csv(clickstream_directory, header=True, inferSchema=True)\n",
    "df_click.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee09a0d-ef0b-4036-a18c-a37ecc48bf6c",
   "metadata": {},
   "source": [
    "### Check for null inside df_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "dac74992-f3d8-42ae-ab19-6ff7066a3f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               % Null\n",
      "fe_1              0.0\n",
      "fe_2              0.0\n",
      "fe_3              0.0\n",
      "fe_4              0.0\n",
      "fe_5              0.0\n",
      "fe_6              0.0\n",
      "fe_7              0.0\n",
      "fe_8              0.0\n",
      "fe_9              0.0\n",
      "fe_10             0.0\n",
      "fe_11             0.0\n",
      "fe_12             0.0\n",
      "fe_13             0.0\n",
      "fe_14             0.0\n",
      "fe_15             0.0\n",
      "fe_16             0.0\n",
      "fe_17             0.0\n",
      "fe_18             0.0\n",
      "fe_19             0.0\n",
      "fe_20             0.0\n",
      "Customer_ID       0.0\n",
      "snapshot_date     0.0\n"
     ]
    }
   ],
   "source": [
    "# Count total rows\n",
    "rows = df_click.count()\n",
    "\n",
    "# Calculate % of nulls per column\n",
    "nulls = df_click.select([\n",
    "    (F.count(F.when(F.col(c).isNull(), c)) / rows * 100).alias(c)\n",
    "    for c in df_click.columns\n",
    "])\n",
    "\n",
    "# Display neatly\n",
    "nulls_df = nulls.toPandas().T\n",
    "nulls_df.columns = ['% Null']\n",
    "print(nulls_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00237dd5-c6a7-4eb8-95df-0a90aebf5c4c",
   "metadata": {},
   "source": [
    "### merge all customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a35fa1b6-886e-4a35-b668-f79a45b500d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = (\n",
    "    df_fin\n",
    "    .join(df_attr, [\"Customer_ID\", \"snapshot_date\"], \"inner\")\n",
    "    .join(df_click, [\"Customer_ID\", \"snapshot_date\"], \"inner\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8930aa91-5eba-44bd-b85d-857adb73f3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Customer_ID: string, snapshot_date: date, Annual_Income: float, Monthly_Inhand_Salary: float, Num_Bank_Accounts: float, Num_Credit_Card: float, Interest_Rate: float, Num_of_Loan: float, Delay_from_due_date: float, Num_of_Delayed_Payment: float, Changed_Credit_Limit: float, Num_Credit_Inquiries: float, Credit_Mix: string, Credit_Utilization_Ratio: float, Payment_Behaviour: string, Credit_History_Age: int, Occupation: string, fe_1: int, fe_2: int, fe_3: int, fe_4: int, fe_5: int, fe_6: int, fe_7: int, fe_8: int, fe_9: int, fe_10: int, fe_11: int, fe_12: int, fe_13: int, fe_14: int, fe_15: int, fe_16: int, fe_17: int, fe_18: int, fe_19: int, fe_20: int]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
